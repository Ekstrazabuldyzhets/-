разбор файла - data_parsing-checkpoint.py
===================================================================================================================================================================
1. Импорты и настройка
python
import sys
import os
import pandas as pd
import matplotlib.pyplot as plt
from scipy.interpolate import interp1d
from multiprocessing import Pool
from tqdm import tqdm
import logging
===================================================================================================================================================================
Multiprocessing - для параллельной обработки файлов
tqdm - для визуализации прогресса
logging - для записи логов выполнения
===================================================================================================================================================================
1) в функции <<if __name__ == '__main__': >> сперва
  - идет получение списка температурных директорий     
    # temperatures = ['25degC', '35degC', '45degC']
  - Обработка C20 калибровочных файлов, запускается функция << process_c20_files(T): >>, 
    в итоге в каждой parsed_data_directory/T/ создается C20_calibration_parsed.csv; Создается пул из 4 процессов; 
    Для каждой температуры запускается асинхронная задача; tqdm отслеживает прогресс (3 задачи для 3 температур)
  - подготовка задач для обработки всех файлов: проходимся по всем найденным папкам temperatures и фиксируем пути к каждой конкретной температурной директории;
    ищем все CSV файлы в дерикториях; обрабатываем каждый файл --> заполняя список tasks к следующему виду:
                                                                tasks = [
                                                                    # 35°C файлы  
                                                                    ('C20_calibration', '35degC'),
                                                                    ('test1', '35degC'),
                                                                    ('test2', '35degC'),
                                                                ]
  - исследуем файлы перебирая tasks, реализуя параллельную обработку всех тестовых файлов, запускается функция << process_file((csv_file_name, T)): >>

2) в функции << process_c20_files(T): >> сперва
  - Поиск C20 файла в сырых данных
  - Обработка найденного C20 файла, запускается функция << parse_raw_data >>, реализующая преобразование начальных, сырых данных к виду со столбцами:
    Timestamp,Time [min],Time [s],Voltage [V],Current [A],Temperature [degC],Capacity [Ah]

2.1) в функции << parse_raw_data() >> сперва на вход фалы вида: Time Stamp,Prog Time,Voltage,Current,Temperature,Capacity
  - Чтение файлов с поиском строки с заголовками столбцов: поиск строки с заголовками столбцов; извлекаем строку - название столбцов; 
    извлекаем строки только данными
  - Обрабатываем данные, проходясь по всем строкам с данными: преобразуем данные в стобце Timestamp в секунды и норамлизуем время для минут и секунд; 
    извлекаем основные числовые данные Voltage [V],Current [A],Temperature [degC],Capacity [Ah]
  - Вместе с тем создаем новый DataFrame с преобразованными данными:
                                              df = pd.DataFrame({
                                                  'Timestamp': abs_timestamp_data,           # Абсолютное время
                                                  'Time [min]': normalized_minutes,          # Относительное время в минутах
                                                  'Time [s]': normalized_seconds,            # Относительное время в секундах  
                                                  'Voltage [V]': voltage_values,             # Напряжение в Вольтах
                                                  'Current [A]': current_values,             # Ток в Амперах
                                                  'Temperature [degC]': temperature_values,  # Температура в °C
                                                  'Capacity [Ah]': capacity_values,          # Емкость в Ампер-часах
                                              })

3) в функции << process_file((csv_file_name, T)): >> сперва
  - Создаем пути к директориям: ../LG_HG2_parsed/25degC/; ../LG_HG2_processed/25degC/; ../LG_HG2_parsed_plots/25degC/; ../LG_HG2_processed_plots/25degC/;
  - Запускаем парсинг сырых данных при помощи функции << parse_raw_data >>, реализующей преобразование начальных, сырых данных к виду со столбцами:
    Timestamp,Time [min],Time [s],Voltage [V],Current [A],Temperature [degC],Capacity [Ah]
  = Созданем графиков без SOC: (напряжение, ток, температура, емкость)
  - Поиск и загрузка калибровочных данных(C20) для расчета значения SOC: 
    получаем функции интерполяции при помощи функции << get_pOCV_SOC_interp_fn(c20_file_path) >>;
    получаем максимальные значения емкости при помощи функции << get_max_capacities(c20_file_path) >>;
    реализуем кулоновский подсчет накопленной емкости: 
                                                                Ёмкость (Ah) = Ток (A) × Время (ч);
    наконец определяем начальный SOC при помощи функции << get_initial_soc(df, charge_soc_fn, discharge_soc_fn, current_col, voltage_col) >>, а затем при
    помощи итерационного расчета находим SOC для каждой точки данных
                                                              Начальный SOC = 0.95 (определен по напряжению)
                                                              Макс. емкость разряда = 2.8 Ah
                                                              Макс. емкость заряда = 2.9 Ah
                                                              
                                                              Время | Ток | Накоп. емкость | Расчет SOC
                                                              0.0   | 0.0 | 0.000          | 0.950 (начальный)
                                                              0.1   | -2.0| -0.00334       | 0.950 - (0.00334/2.8) = 0.9488
                                                              0.2   | -2.0| -0.00668       | 0.950 - (0.00668/2.8) = 0.9476
  - Постобработка данных: Экспоненциальное скользящее среднее убирает шум в данных SOC; удаление дубликатов.
  - Cохранение результатов в файл_processed.csv' и гарфиков SoC

3.1) в функции << get_pOCV_SOC_interp_fn(c20_file_path) >> сперва
  - Загрузка данных C20 и обработка данных
  - Фильтруем данне, отбираются все строки где ток (заряд) отрицательный; нормализуем емкость
  - Расчет SOC для разряда Формула: SOC = 1 - (|текущая_емкость| / |максимальная_емкость_разряда|)
  - Удаляем возможные выбросы напряжения выше максимального -->
  - Создание функции интерполяции для разряда!!!!!!
                                                  x = df_discharge[voltage_col] - напряжение как входной параметр
                                                  y = df_discharge[soc_col] - SOC как выходное значение
                                                  bounds_error=False - не вызывать ошибку при выходе за границы
                                                  fill_value="extrapolate" - экстраполировать значения за пределами данных
  - Фильтруем данне, отбираются все строки где ток (заряд) положительный; нормализуем емкость
  - Удаляем возможные выбросы напряжения выше максимального --> аномально высокие значения напряжения, которые не соответствуют физике батареи, 
    мешают, нарушают интерполяцию и дают неверные значения SOC.
  - Создание функции интерполяции для разряда!!!!!!
                                                  x = df_charge[voltage_col] - напряжение как входной параметр
                                                  y = df_charge[soc_col] - SOC как выходное значение
                                                  bounds_error=False - не вызывать ошибку при выходе за границы
                                                  fill_value="extrapolate" - экстраполировать значения за пределами данных

3.2) в функции << get_max_capacities(c20_file_path) >> сперва
  - Загрузка данных C20 и обработка данных
  - Разделение данных на две части до той точки где произошел переход из разряда в заряд
  - Расчет максимальных емкостей как для ЗАРЯДА так и для РАЗРЯДА

3.3) в функции << get_initial_soc(df, charge_soc_fn, discharge_soc_fn, current_col, voltage_col) >> сперва
  - Получение начального напряжения
  - Поиск первого ненулевого тока
                                                              Index | Current [A]
                                                              ----- | -----------
                                                              0     | 0.000 Исключено (ток = 0)
                                                              1     | -2.000 Включено
                                                              2     | -2.000 Включено
                                                              3     | -1.500 Включено
  - Определение SOC по виду тока; если батарея разряжается используем функцию разряда --> иначе функцию заряда

===================================================================================================================================================================
Система параллельно обрабатывает данные тестирования батарей LG HG2. 
1) калибровочные C20 файлы для создания эталонных кривых "напряжение-SOC". 
2) во всех тестовых файлах, преобразует сырые данные в структурированный формат. 
3) Для каждого файла рассчитывается (SOC) через комбинацию начального напряжения и кулоновского подсчета. 

4) Учитывается гистерезис батареи - разные кривые для заряда и разряда. 
5) Система создает интерполяционные функции, связывающие напряжение с SOC. 

6) Параллельная обработка ускоряет работу с множеством файлов. 

ИТОГ: Результаты включают данные с SOC и визуализацию в виде графиков. 
===================================================================================================================================================================
В чем важность обработки C20 файла - ?

C20 - это тест при токе, при котором батарея разряжается за 20 часов:
Для батареи 3Ah: ток C20 = 3Ah / 20h = 0.15A
Этот режим считается "щадящим" и дает наиболее точное значение реальной емкости
Без C20: Мы не знаем реальную максимальную емкость батареи
С C20: Мы точно знаем max_charge_capacity и max_discharge_capacity
===================================================================================================================================================================
Что за гимстерзис - ?

Гистерезис в данных о состоянии заряда (SoC) аккумулятора означает разницу в кривой зависимости напряжения от заряда между процессами зарядки и разрядки.

===================================================================================================================================================================
Создание функции интерполяции - ?
Интерполяция — это процесс нахождения промежуточных значений некоторой функции или данных, которые находятся внутри известного диапазона. 

Ограниченное количество калибровочных точек (напряжение) из C20 теста, но в реальных данных напряжения могут принимать любые значения между этими точками.
Интерполяция позволяет "достраивать" значения между известными точками и получать SOC для любого напряжения.

использцется функция interp1d from scipy.interpolate
                                                      x - известные значения напряжения (исходные данные)
                                                      y - известные значения SOC (исходные данные)
                                                      bounds_error=False - не вызывать ошибку при выходе за границы
                                                      fill_value="extrapolate" - экстраполировать значения за пределами данных
(x, y) -н-> узлами интерполяции
Наиболее простым методом является линейная интерполяция, когда предполагается, что промежуточные точки лежат на прямых, в нашем случае По умолчанию он 
"линейный".

===================================================================================================================================================================
разбор файла - SoC_Estimation_LSTM.py 
0) Проверяется наличие GPU для ускорения вычислений через CUDA.
===================================================================================================================================================================
0*) Настройка параметров
  - установка флагов и констант

1) Загрузка и подготовка данных (стр 79 - 139) сперва
  - загрузка данны при помощи функции << load_data(PROCESSED_DATA_DIR, temperatures_to_process) >> на вход которой подается
                                                                              Параметры:
                                              directory: '/Users/nierra/Desktop/диплом-2/датасет_2/LG_HG2_processed'
                                              temperatures: ['25degC', '0degC', 'n10degC', 'n20degC', '10degC', '40degC']
  - нормализуем данные и разделяем на три выборки (обучающую, валидацимонную и тестовую) с дальнейшим созданием разделенных наборов данных

1.1) в функции << load_data(PROCESSED_DATA_DIR, temperatures_to_process) >> сперва
  - Обход всех температурных директорий в temperatures
  - Обход файлов в каждой температурной директории; Пропускаем файлы постоянного заряда/разряда так как
    Постоянный ток не создает интересных временных паттернов LSTM лучше учится на динамических, изменяющихся режимах работы
                                                            PROCESSED_DATA_DIR/
                                                            ├── 25degC/
                                                            │   ├── test1_processed.csv → DataFrame1 + Power + CC_Capacity
                                                            │   ├── test2_processed.csv → DataFrame2 + Power + CC_Capacity
                                                            │   └── C20_calibration_parsed.csv → DataFrame3 + Power + CC_Capacity
                                                            ├── 0degC/
                                                            │   ├── test1_processed.csv → DataFrame4 + Power + CC_Capacity
                                                            │   └── test2_processed.csv → DataFrame5 + Power + CC_Capacity
                                                            ├── n10degC/
                                                            │   └── ... → DataFrame6 + Power + CC_Capacity
                                                            └── ...
                                                            
                                                                ↓ pd.concat() объединяет ВСЕ

2) Создание Dataset и DataLoader --> они обеспечивают потоковую подачу данных прямо на GPU, ускоряет тренировку модели сперва
  - В результате создается объект, который знает: Где находятся данные (тензоры на GPU); Какой длины должны быть последовательности (20 шагов); 
    Дополнительную метаинформацию (имена файлов, время)
  - Создание Dataset объектов при помощи функции << BatteryDatasetLSTM >> Dataset подготавливает данные в формате, понятном нейросети преобразует 
    временные ряды данных батареи в последовательности для обучения LSTM.. 
  - Создание DataLoader при помощи функции втроеннной << DataLoader >> DataLoader автоматически разбивает эти данные на батчи 
    для эффективной обработки и перемешивает их для улучшения обучения. 

2.1) в классе << BatteryDatasetLSTM >> сперва --? НУЖНО БОЛЬШЕ РАЗБИРАТЕЛЬСТВ КАК РАБОТАЕТ КЛАСС
  - инициализируем Конструктор, задающий 
                                                self.sequence_length = sequence_length  # 20 (длина последовательности)
                                                self.features = data_tensor            # Тензор признаков [n_samples, 5_features]
                                                self.labels = labels_tensor            # Тензор меток SOC [n_samples]
                                                self.filenames = filenames             # Массив имен файлов
                                                self.times = times                     # Массив временных меток
  - при помощи Метода __len__: мы решаем проблему выхода за пределы 
    Например массив имеет только 441,453 элементов, а мы пытаемся взять до 441,472 - это вызовет ошибку(последовательность 20).
    количество_последовательностей = общее_количество_точек - длина_последовательности
  - при помощи Метода __getitem__ позволяет объекту вести себя как последовательность (как список или словарь).
  - при помощи Метода get_unique_filenames() мы можем получить уникальные имена файлов в датасете для анализа разделения данных.
  - при помощи Метода get_times() мы можем получить все временные метки для анализа временных характеристик.
  
3) Подбор гиперпараметров при помощи Optuna сперва
  - создает объект исследования direction='minimize' указывает, что мы хотим минимизировать целевую функцию (val_loss), после чего запускаем
    Optuna, он в свою очередь запускает 10 "испытаний" (trials), каждое с разными гиперпараметрами. 
  - Вместе с тем при помощи функции << objective(trial) >> определим целевую функцию Optuna, эта функция получает от Optuna набор гиперпараметров, 
    создает и обучает LSTM модель с этими параметрами, и возвращает значение валидационной ошибки, чтобы Optuna могла найти комбинацию параметров, 
    которая минимизирует эту ошибку.
  - Извлекаем лучшую версию trial а также лучшие гиперпараметры которые были для нее использованы
  - Добавляем визуализацию важности параметров и процесса обучения

3.1) в функции  << objective(trial) >> сперва
  - сперва идет получение параметров (hidden_size - нейроны; num_layers - количество слоев LSTM; learning_rate - скоростью обучения Adam), 
    где Optuna выступает в роли "советчик"
  - сборка испытательной модели при помощи класса << SoCLSTM >>, он анализирует последовательность из 20 последних измерений параметров 
    батареи (напряжение, ток, температура, мощность, емкость) и предсказывает текущее состояние заряда (SOC) на основе выученных временных зависимостей.  
  - проводим анализ, настраиваем оптимизацию, имеряя ошибку а также создаем Эта строка создает оптимизатор Adam, 
    который будет обновлять веса нейронной сети в процессе обучения, используя алгоритм адаптивной градиентной оптимизации.
  - Обучение и оценка - Проведение "эксперимента" производится при помощи функции << train_and_validate >>, она итеративно обучает модель на тренировочных данных, 
    одновременно проверяя ее качество на валидационных данных, и автоматически останавливает обучение когда модель перестает улучшаться, 
    предотвращая переобучение.
  - Возврат отчета о "качестве"

                                                                    Итоговая схема:
                                            Trial.start()
                                                ↓
                                            objective(trial)
                                                ├── trial.suggest_*() × 3  # Получить гиперпараметры
                                                ├── SoCLSTM()             # Создать модель
                                                ├── optim.Adam()          # Создать оптимизатор  
                                                ├── train_and_validate()  # Обучить 10 эпох
                                                │   ├── model.train() → forward → loss → backward → step (много раз)
                                                │   └── model.eval() → forward (валидация)
                                                └── return val_loss       # Вернуть качество

3.2) в классе << SoCLSTM >> сперва
  - создается архетиктура класса
                                                            SoCLSTM(
                                                              (lstm): LSTM(5, 73, num_layers=4, batch_first=True)
                                                              (fc): Linear(in_features=73, out_features=1, bias=True)
                                                            )
  - Прямой проход (в функции forward): Инициализация скрытых состояний h0: начальное hidden state - краткосрочная память
    c0: начальное cell state - долгосрочная память
                                                  Как работает LSTM на каждом шаге:
                                            Для каждого из 20 временных шагов LSTM выполняет:
                                                  
                                                  LSTM ячейка - внутренняя структура:
                                                  text
                                                  Вход: x_t (5 features) + h_{t-1} (73) + c_{t-1} (73)
                                                      ↓
                                                  1. Forget Gate: f_t = σ(W_f · [h_{t-1}, x_t] + b_f)
                                                     - Решает какую информацию забыть из долгосрочной памяти
                                                  
                                                  2. Input Gate: i_t = σ(W_i · [h_{t-1}, x_t] + b_i)
                                                     - Решает какую новую информацию запомнить
                                                  
                                                  3. Candidate Memory: g_t = tanh(W_g · [h_{t-1}, x_t] + b_g)  
                                                     - Создает кандидата для обновления памяти
                                                  
                                                  4. Cell State Update: c_t = f_t * c_{t-1} + i_t * g_t
                                                     - Обновляет долгосрочную память
                                                  
                                                  5. Output Gate: o_t = σ(W_o · [h_{t-1}, x_t] + b_o)
                                                     - Решает какую информацию вывести
                                                  
                                                  6. Hidden State: h_t = o_t * tanh(c_t)
                                                     - Обновляет краткосрочную память
Визуализация полного прохода:
text
Вход: [128, 20, 5]
    ↓ LSTM слой 1 → [128, 20, 73] (запоминает краткосрочные зависимости)
    ↓ LSTM слой 2 → [128, 20, 73] (извлекает более сложные паттерны)  
    ↓ LSTM слой 3 → [128, 20, 73] (анализирует долгосрочные тренды)
    ↓ LSTM слой 4 → [128, 20, 73] (интегрирует всю информацию)
    ↓ out[:, -1, :] → [128, 73] (берем финальное состояние)
    ↓ FC слой → [128, 1] (преобразуем в одно число - SOC)
Выход: [128, 1] - предсказанные значения SOC

3.3) в функции << train_and_validate >> сперва
  - Инициализация, где мы создаем history: словарь для отслеживания потерь, best_val_loss: лучшее значение валидационной потери,
    epochs_no_improve: счетчик эпох без улучшений
  - Идем по эпохам - один полный проход через все тренировочные данные.
  - 

4) После того как все гиперпараметры подобраны производим финальное обчение
  - Создание модели с лучшими параметрами
  - Настройка оптимизатора и функции потерь
  - Обучение модели в функции << train_and_validate >>
  - визуализация обучения и сохранение модели в << model_state_dict.pth >>

5) Тестирование модели
  - загрузка модели в функции << load_lstm_model >>
  - ее тестировка в функции 

5.1) в функции << load_lstm_model >> сперва
  - Создание экземпляра при помощи класа SoCLSTM
  - Загрузка сохраненных весов при помощи встроенной функции << load_state_dict >>
  - Дополнительное перемещение на устройство, чтобы гарантировать, что загруженные веса находятся на правильном устройстве
  - eval() переключение в режим оценки

5.2) в функции << test_model >> сперва 
  - Создание
